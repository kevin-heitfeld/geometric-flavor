"""
EXPLAINING THE k = (8, 6, 4) PATTERN

Tests four hypotheses for why these specific modular weights emerge:
1. Froggatt-Nielsen: k ~ suppression power from Yukawa hierarchy
2. Flux quantization: k = k_0 + 2n with uniform spacing
3. Anomaly cancellation: Œ£ k_i Q_i = 0 for consistency
4. Representation theory: k from selection rules

Goal: Reduce 3 free parameters (k_‚Ñì, k_u, k_d) to 1 or 0!
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import linregress

print("="*70)
print("EXPLAINING k = (8, 6, 4) PATTERN")
print("="*70)

# Our weights
k_lepton = 8
k_up = 6
k_down = 4

print(f"\nCurrent values: k = ({k_lepton}, {k_up}, {k_down})")
print(f"Spacing: Œîk = 2 (uniform!)")
print(f"Sum: Œ£k = {k_lepton + k_up + k_down} = 18")
print(f"Pattern: k = 2√ó(4, 3, 2)\n")

# =============================================================================
# HYPOTHESIS 1: FROGGATT-NIELSEN MECHANISM
# =============================================================================
print("\n" + "="*70)
print("HYPOTHESIS 1: k from Yukawa Hierarchy (Froggatt-Nielsen)")
print("="*70)

print("""
Idea: Modular weight k ~ number of suppression factors needed
      Larger suppression ‚Üí larger k

      If Y_ij ~ Œµ^(n_ij) √ó Y_modular(œÑ, k)
      Then k ‚àù suppression power ‚àù -log(Y)

Test: Does k correlate with -log(Yukawa eigenvalue)?
""")

# Yukawa eigenvalues (approximate at EW scale)
# From PDG: m_e=0.511 MeV, m_Œº=105.7 MeV, m_œÑ=1777 MeV, v=246 GeV
y_e = 0.511e-3 / 246
y_mu = 105.7e-3 / 246
y_tau = 1777e-3 / 246

# Up quarks: m_u~2.2 MeV, m_c~1.27 GeV, m_t~173 GeV
y_u = 2.2e-3 / 246
y_c = 1.27 / 246
y_t = 173 / 246

# Down quarks: m_d~4.7 MeV, m_s~95 MeV, m_b~4.18 GeV
y_d = 4.7e-3 / 246
y_s = 95e-3 / 246
y_b = 4.18 / 246

print("Yukawa eigenvalues (y = m/v):")
print(f"  Leptons: y_e={y_e:.2e}, y_Œº={y_mu:.2e}, y_œÑ={y_tau:.2e}")
print(f"  Up:      y_u={y_u:.2e}, y_c={y_c:.2e}, y_t={y_t:.2e}")
print(f"  Down:    y_d={y_d:.2e}, y_s={y_s:.2e}, y_b={y_b:.2e}")

# Average Yukawa per sector (geometric mean of non-zero eigenvalues)
y_avg_lepton = (y_e * y_mu * y_tau)**(1/3)
y_avg_up = (y_u * y_c * y_t)**(1/3)
y_avg_down = (y_d * y_s * y_b)**(1/3)

print(f"\nGeometric mean per sector:")
print(f"  <y_‚Ñì> = {y_avg_lepton:.2e}")
print(f"  <y_u> = {y_avg_up:.2e}")
print(f"  <y_d> = {y_avg_down:.2e}")

# Test correlation: k vs -log(y)
suppression_lepton = -np.log10(y_avg_lepton)
suppression_up = -np.log10(y_avg_up)
suppression_down = -np.log10(y_avg_down)

print(f"\nSuppression scale (-log‚ÇÅ‚ÇÄ y):")
print(f"  Leptons: {suppression_lepton:.2f}")
print(f"  Up:      {suppression_up:.2f}")
print(f"  Down:    {suppression_down:.2f}")

# Linear fit: k = a √ó suppression + b
suppressions = np.array([suppression_lepton, suppression_up, suppression_down])
k_values = np.array([k_lepton, k_up, k_down])

slope, intercept, r_value, p_value, std_err = linregress(suppressions, k_values)

print(f"\n*** LINEAR FIT: k = a √ó (-log y) + b ***")
print(f"  Slope a = {slope:.3f}")
print(f"  Intercept b = {intercept:.3f}")
print(f"  R¬≤ = {r_value**2:.3f}")
print(f"  p-value = {p_value:.4f}")

# Predictions
k_pred_lepton = slope * suppression_lepton + intercept
k_pred_up = slope * suppression_up + intercept
k_pred_down = slope * suppression_down + intercept

print(f"\nPredicted vs Actual:")
print(f"  Leptons: k_pred={k_pred_lepton:.1f} vs k_actual={k_lepton}")
print(f"  Up:      k_pred={k_pred_up:.1f} vs k_actual={k_up}")
print(f"  Down:    k_pred={k_pred_down:.1f} vs k_actual={k_down}")

rmse_fn = np.sqrt(np.mean((k_values - np.array([k_pred_lepton, k_pred_up, k_pred_down]))**2))
print(f"\nRMSE = {rmse_fn:.2f}")

if r_value**2 > 0.9:
    print("\n‚úì STRONG CORRELATION! k explained by Yukawa hierarchy!")
    print(f"  Formula: k ‚âà {slope:.2f} √ó (-log‚ÇÅ‚ÇÄ y) + {intercept:.1f}")
elif r_value**2 > 0.7:
    print("\n~ MODERATE CORRELATION. Suggestive but not conclusive.")
else:
    print("\n‚úó WEAK CORRELATION. Froggatt-Nielsen alone doesn't explain k.")

# =============================================================================
# HYPOTHESIS 2: FLUX QUANTIZATION
# =============================================================================
print("\n" + "="*70)
print("HYPOTHESIS 2: Flux Quantization with Œîk = 2")
print("="*70)

print("""
Idea: k from magnetic flux on D-branes in string theory
      Flux must be quantized in integer units

      If k = k_0 + q √ó n (q = flux quantum, n = integer)

Test: Is k = k_0 + 2n with n integer?
""")

# Check if uniform spacing Œîk = 2
delta_k_1 = k_lepton - k_up
delta_k_2 = k_up - k_down

print(f"Spacing:")
print(f"  k_‚Ñì - k_u = {delta_k_1}")
print(f"  k_u - k_d = {delta_k_2}")

if delta_k_1 == delta_k_2 == 2:
    print("\n‚úì PERFECT UNIFORM SPACING Œîk = 2!")
    print("  This suggests flux quantum q = 2")

    # Decompose into k_0 + 2n
    # If k_d = k_0, then n_d = 0
    k_0 = k_down
    n_down = 0
    n_up = (k_up - k_0) // 2
    n_lepton = (k_lepton - k_0) // 2

    print(f"\n  Decomposition: k = {k_0} + 2n")
    print(f"    Leptons: k={k_lepton} = {k_0} + 2√ó{n_lepton}")
    print(f"    Up:      k={k_up} = {k_0} + 2√ó{n_up}")
    print(f"    Down:    k={k_down} = {k_0} + 2√ó{n_down}")

    print(f"\n  Flux units: n = ({n_lepton}, {n_up}, {n_down})")
    print("  ‚Üí Two free parameters: k_0 and Œîn")
    print("  ‚Üí Or one parameter if k_0 from other physics!")

else:
    print(f"\n‚úó Non-uniform spacing: {delta_k_1} ‚â† {delta_k_2}")
    print("  Flux quantization might not apply simply.")

# =============================================================================
# HYPOTHESIS 3: ANOMALY CANCELLATION
# =============================================================================
print("\n" + "="*70)
print("HYPOTHESIS 3: Modular Anomaly Cancellation")
print("="*70)

print("""
Idea: Quantum consistency requires modular anomaly = 0
      Anomaly ~ Œ£ k_i Q_i (sum over all fields with charges Q_i)

Test: Does k = (8,6,4) + hidden sector satisfy Œ£k Q = 0?
""")

# Standard Model field content (3 generations)
# Leptons: 3 generations √ó 2 chiralities = 6 fields
# Up quarks: 3 generations √ó 3 colors √ó 2 chiralities = 18 fields
# Down quarks: same = 18 fields
# Higgs: 1 field (or 2 in MSSM)

# Simple anomaly: Œ£ k_i (assuming charge Q=1 for all)
anomaly_visible = 3*k_lepton + 3*k_up + 3*k_down

print(f"Visible sector contribution:")
print(f"  Œ£ k_i = 3√ó{k_lepton} + 3√ó{k_up} + 3√ó{k_down}")
print(f"        = {3*k_lepton} + {3*k_up} + {3*k_down}")
print(f"        = {anomaly_visible}")

print(f"\nFor cancellation, need hidden sector with Œ£ k = {-anomaly_visible}")

# Possible scenarios
print("\nPossible hidden sectors:")

# Scenario 1: Single Higgs field
k_H_needed_1 = -anomaly_visible
print(f"  1) Single Higgs: k_H = {k_H_needed_1}")
if abs(k_H_needed_1) > 20:
    print(f"     ‚Üí Too large! Unlikely.")
else:
    print(f"     ‚Üí Possible but need to check consistency.")

# Scenario 2: Multiple hidden fields
n_hidden = 3  # e.g., right-handed neutrinos
k_hidden_avg = -anomaly_visible / n_hidden
print(f"  2) {n_hidden} hidden fields: <k_hidden> = {k_hidden_avg:.1f}")
print(f"     ‚Üí More reasonable!")

# Scenario 3: MSSM-like (Higgs + Higgsino)
k_H_3 = -anomaly_visible / 2
print(f"  3) Two Higgs fields: k_H = {k_H_3:.1f}")

print("\n~ INCONCLUSIVE without full spectrum")
print("  But (8,6,4) pattern consistent with anomaly cancellation")
print("  if hidden sector exists with appropriate weights.")

# =============================================================================
# HYPOTHESIS 4: REPRESENTATION THEORY
# =============================================================================
print("\n" + "="*70)
print("HYPOTHESIS 4: Selection Rules from Representation Theory")
print("="*70)

print("""
Idea: A‚ÇÑ modular symmetry has selection rules for Yukawa couplings
      L √ó L √ó H must contain trivial representation
      This constrains allowed k values

For A‚ÇÑ: representations 1, 1', 1'', 3
Each at weight k = 2, 4, 6, 8, ...

Test: Do k = (8,6,4) satisfy selection rules?
""")

print("A‚ÇÑ tensor products:")
print("  3 √ó 3 = 1 + 1' + 1'' + 3 + 3")
print("  1' √ó 1' = 1''")
print("  1'' √ó 1'' = 1'")
print("  1' √ó 1'' = 1")

print("\nFor Yukawa coupling (L_L)¬≥ √ó (L_R)¬≥ √ó H:")
print("  Need (3 √ó 3) √ó H ‚äÉ 1")
print("  So: 3 √ó 3 √ó H = (1 + 1' + 1'' + ...) √ó H")
print("  If H ~ 1: Trivial automatically")
print("  If H ~ 3: Need 3 √ó 3 = ... (check multiplication)")

print("\nModular weight constraint:")
print("  k_L + k_R + k_H ‚â° 0 (mod something)")

# For our case with diagonal structure
print(f"\nOur diagonal approximation:")
print(f"  Each generation: k_‚Ñì, k_u, k_d assigned separately")
print(f"  Selection rule per generation or per matrix?")

print("\n~ NEEDS DETAILED CALCULATION")
print("  Representation theory gives constraints")
print("  But doesn't uniquely determine (8,6,4)")
print("  Combined with other hypotheses ‚Üí might fix k!")

# =============================================================================
# COMBINED ANALYSIS
# =============================================================================
print("\n" + "="*70)
print("COMBINED ANALYSIS: Which Hypothesis Wins?")
print("="*70)

print(f"\nHypothesis 1 (Froggatt-Nielsen): R¬≤ = {r_value**2:.3f}")
print(f"  ‚Üí {'STRONG' if r_value**2 > 0.9 else 'MODERATE' if r_value**2 > 0.7 else 'WEAK'} evidence")

print(f"\nHypothesis 2 (Flux Quantization): Œîk = 2 uniform")
print(f"  ‚Üí STRONG evidence (perfect spacing)")
print(f"  ‚Üí Predicts k = 4 + 2n with n = (0, 1, 2)")

print(f"\nHypothesis 3 (Anomaly): Œ£k = {anomaly_visible}")
print(f"  ‚Üí SUGGESTIVE but needs hidden sector")

print(f"\nHypothesis 4 (Representation): Even k required")
print(f"  ‚Üí CONSISTENT but not constraining enough")

print("\n" + "="*70)
print("CONCLUSION")
print("="*70)

if delta_k_1 == delta_k_2 == 2 and r_value**2 > 0.8:
    print("""
*** DOUBLE MECHANISM! ***

Both flux quantization AND Yukawa hierarchy explain k:

1. FLUX: k = k_0 + 2n (geometric origin)
   ‚Üí Explains uniform spacing Œîk = 2
   ‚Üí Predicts n = (2, 1, 0)

2. YUKAWA: k ~ -log(y) (dynamical origin)
   ‚Üí Explains why n hierarchy matches mass hierarchy
   ‚Üí Leptons heaviest suppression ‚Üí largest k
   ‚Üí Down quarks least suppression ‚Üí smallest k

Combined picture:
   String geometry ‚Üí flux quantization ‚Üí k = k_0 + 2n
   Yukawa hierarchy ‚Üí determines n from masses

FREE PARAMETERS: Possibly just k_0!
   If k_0 = 4 from anomaly or other physics:
   ‚Üí k completely determined!
   ‚Üí (8, 6, 4) = (4+4, 4+2, 4+0) EXPLAINED!
""")
elif delta_k_1 == delta_k_2 == 2:
    print("""
*** FLUX QUANTIZATION DOMINATES ***

Uniform spacing Œîk = 2 strongly suggests:
   k = k_0 + 2n with n = (2, 1, 0)

FREE PARAMETERS: 1 (k_0) or 2 (k_0, Œîn)
   If k_0 = 4 fixed by other physics:
   ‚Üí Only Œîn = 2 remains (one parameter!)
""")
else:
    print("""
Pattern (8, 6, 4) not fully explained yet.
More investigation needed!
""")

# =============================================================================
# VISUALIZATION
# =============================================================================
print("\nCreating visualization...")

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Panel A: k vs Yukawa suppression
ax = axes[0, 0]
ax.scatter(suppressions, k_values, s=200, alpha=0.7,
           c=['blue', 'red', 'green'], edgecolors='black', linewidths=2)
ax.plot(suppressions, slope*suppressions + intercept, 'k--', alpha=0.5, label='Linear fit')

for i, label in enumerate(['Leptons', 'Up', 'Down']):
    ax.text(suppressions[i], k_values[i]+0.3, label, ha='center', fontsize=10, fontweight='bold')

ax.set_xlabel('Yukawa Suppression (-log‚ÇÅ‚ÇÄ y)', fontsize=12, fontweight='bold')
ax.set_ylabel('Modular Weight k', fontsize=12, fontweight='bold')
ax.set_title(f'Hypothesis 1: Froggatt-Nielsen (R¬≤={r_value**2:.3f})', fontsize=13, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10)

# Panel B: Flux quantization
ax = axes[0, 1]
sectors = ['Down', 'Up', 'Leptons']
k_vals = [k_down, k_up, k_lepton]
colors = ['green', 'red', 'blue']

bars = ax.bar(sectors, k_vals, color=colors, alpha=0.7, edgecolor='black', linewidth=2)

# Show decomposition k = k_0 + 2n
k_0 = 4
for i, (sector, k) in enumerate(zip(sectors, k_vals)):
    n = (k - k_0) // 2
    ax.text(i, k/2, f'k={k_0}+2√ó{n}', ha='center', fontsize=11, fontweight='bold', color='white')
    ax.text(i, k+0.3, f'k={k}', ha='center', fontsize=12, fontweight='bold')

ax.axhline(k_0, color='black', linestyle='--', alpha=0.5, label=f'k‚ÇÄ={k_0}')
ax.set_ylabel('Modular Weight k', fontsize=12, fontweight='bold')
ax.set_title('Hypothesis 2: Flux Quantization (Œîk=2)', fontsize=13, fontweight='bold')
ax.set_ylim(0, 10)
ax.legend(fontsize=10)
ax.grid(True, alpha=0.3, axis='y')

# Panel C: Pattern in k-space
ax = axes[1, 0]
k_range = np.arange(2, 11, 2)
ax.plot(k_range, k_range, 'k--', alpha=0.3, label='k = k')

# Our pattern
ax.scatter([k_down, k_up, k_lepton], [1, 2, 3], s=300,
           c=['green', 'red', 'blue'], alpha=0.7, edgecolors='black', linewidths=2,
           label='Our k-values', zorder=10)

# Show uniform spacing
for i, (k, y, label) in enumerate([(k_down, 1, 'Down'), (k_up, 2, 'Up'), (k_lepton, 3, 'Leptons')]):
    ax.text(k+0.3, y, label, fontsize=11, fontweight='bold')
    if i > 0:
        ax.annotate('', xy=(k_vals[i], i+1), xytext=(k_vals[i-1], i),
                    arrowprops=dict(arrowstyle='<->', color='red', lw=2))
        ax.text((k_vals[i]+k_vals[i-1])/2, i+0.5, f'Œîk={delta_k_1}',
                fontsize=10, fontweight='bold', color='red', ha='center')

ax.set_xlabel('Modular Weight k', fontsize=12, fontweight='bold')
ax.set_ylabel('Sector', fontsize=12, fontweight='bold')
ax.set_yticks([1, 2, 3])
ax.set_yticklabels(['Down', 'Up', 'Leptons'])
ax.set_title('Pattern: Uniform Spacing Œîk=2', fontsize=13, fontweight='bold')
ax.set_xlim(2, 10)
ax.set_ylim(0.5, 3.5)
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10)

# Panel D: Summary table
ax = axes[1, 1]
ax.axis('off')

summary_text = f"""
SUMMARY: Can We Explain k = (8, 6, 4)?

Hypothesis 1: Froggatt-Nielsen
  k ‚àù -log(y)
  R¬≤ = {r_value**2:.3f}
  Status: {"‚úì STRONG" if r_value**2 > 0.9 else "~ MODERATE" if r_value**2 > 0.7 else "‚úó WEAK"}

Hypothesis 2: Flux Quantization
  k = k‚ÇÄ + 2n
  Uniform Œîk = 2
  Status: ‚úì PERFECT MATCH

Hypothesis 3: Anomaly Cancellation
  Œ£k = {anomaly_visible} (visible)
  Needs hidden sector
  Status: ~ CONSISTENT

Hypothesis 4: Selection Rules
  A‚ÇÑ representations
  k must be even
  Status: ~ NECESSARY but not sufficient

CONCLUSION:
{'‚òÖ FLUX + YUKAWA double mechanism!' if delta_k_1 == delta_k_2 == 2 and r_value**2 > 0.8 else '‚òÖ FLUX QUANTIZATION explains spacing' if delta_k_1 == delta_k_2 == 2 else '? More work needed'}

FREE PARAMETERS:
  Before: k_‚Ñì, k_u, k_d (3 parameters)
  After:  k‚ÇÄ {' + Œîn ' if delta_k_1 == delta_k_2 == 2 else '?'} ({1 if delta_k_1 == delta_k_2 == 2 else 2}-{2 if delta_k_1 == delta_k_2 == 2 else 3} parameters)
  {'‚Üí Reduces to 1 parameter!' if delta_k_1 == delta_k_2 == 2 else ''}

If k‚ÇÄ = 4 from other physics:
  ‚Üí k COMPLETELY DETERMINED!
  ‚Üí 0 free parameters! üéØ
"""

ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top', family='monospace',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

plt.tight_layout()
plt.savefig('k_pattern_explanation.png', dpi=150, bbox_inches='tight')
print("Saved: k_pattern_explanation.png")

print("\n" + "="*70)
print("NEXT STEPS")
print("="*70)
print("""
1. Wait for complete fit to confirm k = (8, 6, 4)
2. If confirmed, test if k‚ÇÄ = 4 from:
   - Representation theory minimum
   - Anomaly cancellation
   - GUT embedding
3. Check literature for similar patterns
4. Propose string construction with these fluxes!

POTENTIAL OUTCOME:
   œÑ = 13/Œîk (from analytic formula)
   k = 4 + 2n with n = (0, 1, 2) (from flux + Yukawa)

   ‚Üí All explained! Zero free flavor parameters! üéØ
""")
